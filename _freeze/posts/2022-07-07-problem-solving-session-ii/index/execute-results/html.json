{
  "hash": "23f7d8ade7c0c0931d2943df678d095a",
  "result": {
    "markdown": "---\ntitle: Problem Solving Session II\nauthor: ''\ndate: '2022-07-07'\nslug: []\ncategories: []\ntags:\n  - blogdown\n  - r\n  - raster\n  - terra\n  - arcpy\n  - RAM\nDescription: 'Problem solving session II'\nTags: []\noutput:\n  blogdown::html_page:\n    toc: true\nCategories: []\nDisableComments: no\n---\n\n\n# Problem solving session II\n\n<br>\n\nFollowing the success of our last problem solving session, we ran another one in June.\n\n<!-- image for icon ![](https://c.tenor.com/dlJSiLUJNmsAAAAC/math-calculate.gif) -->\n<img src=\"https://m.media-amazon.com/images/I/81nKJATxK2L._AC_SX679_.jpg\" width=\"200\"/>\n\nWe had interesting and wide-ranging discussions about the issues people are having with geospatial analysis.\\\nBelow are some of the key issues / contributions / suggestions that came up.\n\n## Six tips for processing big rasters in R - Lorna Hernandez-Santin\n\nLorna has been processing some massive raster datasets in R, and has been running into persistent RAM issues. The code below contains a few tricks of the trade to try to help get you up and running if you are running into RAM issues.\n\n### 1. change RAM allocated to R.\n\nThis includes a section about changing the RAM allocated to java - which is required for the species distribution modelling package MaxEnt.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#increase RAM allocation; once increased you cannot decrease it until you restart your session\nmemory.limit(8000)\nmemory.limit(5000) #is ignored\n###check current RAM allocation\nmemory.limit()\n\n#if you restart r session it goes back to original RAM allocation\nmemory.limit()\n####\n# change RAM allocated to java (heap space)\n###\n#more niche, but java is needed to run MaxEnt (species distribution modelling)\n#settings need to be changed before opening the library\noptions(java.parameters = c(\"-XX:+UseConcMarkSweepGC\", \"-Xmx16000m\"))\n```\n:::\n\n\n## 2. change RAM allocated to process rasters\n\nYou can also increase the RAM available to specific packages - namely the `raster` and `terra` packages:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n###with raster package\n\n#check allocated fraction (and other raster settings, including temporary directory)\nrasterOptions()\n\n#can increase or decrease in same session\nrasterOptions(memfrac=0.9)\nrasterOptions(memfrac=0.3)\n\n#restarting session goes back to original allocation\n```\n:::\n\n\nwith terra package; Mitch showed us: <https://geospatial-community.netlify.app/post/2022-02-23-raster-analysis/>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(terra)\nterraOptions()\nterraOptions(memfrac=0.7)\n\n#and you can also change the temp directory directly for terra... but only terra\nterraOptions(memfrac=0.2, tempdir = \"R:/big_drive/Trial\")\n```\n:::\n\n\n## 3. Move temporary directory to a different folder\n\nAs described [here](https://stackoverflow.com/questions/17107206/change-temporary-directory), you can change the temp directory so it doesn't fill up your computer.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSys.getenv() #to check all setting of the environment\n\n#check the directories now\nSys.getenv(\"TMPDIR\",\"TMP\",\"TEMP\")\n\n#each path needs to be specifically written (otherwise it doesnt work, because of the quotations) \ntochange<-c(\"TMPDIR = 'R:/large_disk/RtempFiles'\",\n            \"TMP = 'R:/large_disk/RtempFiles'\",\n            \"TEMP = 'R:/large_disk/RtempFiles'\")\n#\"R:/large_disk/Trial\"\n\n#write the file as .Renviron in your associated user path (R_USER)\nwrite(tochange, sep=\"c\", file=file.path(Sys.getenv('R_USER'), '.Renviron'))\nSys.getenv('R_USER') #the path where the file was written\n\n#restart session, can be without closing R\nSys.getenv(\"TMPDIR\",\"TMP\",\"TEMP\")\n```\n:::\n\n\n## 4. parallel processing\n\nBy default, R uses only one core;but most computers these days have multiple cores\n\n[Here](https://www.r-bloggers.com/2019/01/are-you-parallelizing-your-raster-operations-you-should/) is a summary.\n\nHere are 2 ways to do this. ###1.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#specific to an operation, but cannot do many raster operations\nclusterR(x, fun, args=NULL, cl=mycluster)\n```\n:::\n\n\n###2.\\\nThis is the easiest, because you can put anything you need in between\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbeginCluster()\nendCluster()\n```\n:::\n\n\nAs an example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#e.g.\nParentDir<-\"R:\\\\FITZBIO-A6478\\\\4_Analysis\\\\R\\\\1_HSModel\\\\2_RasterTifs\\\\F3_90m\"\nLayer1 <-raster(file.path(paste0(ParentDir,\"\\\\Bio1.tif\")))\nLayer2 <-raster(file.path(paste0(ParentDir,\"\\\\Bio2.tif\")))\n#plot(Layer1) \n#plot(Layer2)\n#without using multiple cores\nstart_time <- Sys.time()\ns<-stack(Layer1,Layer2)\nLay1xLay2<-overlay(s, fun=function(x,y) x*y )\nend_time <- Sys.time()\nNoCore<-end_time - start_time\n\n#using multiple cores, but measuring time only of the process itself\nbeginCluster()\nstart_time <- Sys.time()\ns<-stack(Layer1,Layer2)\nLay1xLay2<-overlay(s, fun=function(x,y) x*y )\nend_time <- Sys.time()\nendCluster()\nTimeExlcudeCore<-end_time - start_time\n\n#using multiple cores, measuring time of whole process (including parallelizing)\nstart_time <- Sys.time()\nbeginCluster()\ns<-stack(Layer1,Layer2)\nLay1xLay2<-overlay(s, fun=function(x,y) x*y )\nendCluster()\nend_time <- Sys.time()\nTimeIncludeCore<-end_time - start_time\n\n#check time results\nNoCore\nTimeExlcudeCore\nTimeIncludeCore\n#when preparing this, sometimes I got same results sometimes I didn't\n```\n:::\n\n\n## 5. Free up memory\n\nRunning `gc()` gets rid of temp files, so be sure to save results needed and not do it half way through a process that relies on temp files\n\n## 6. change resolution\n\nIf all else fails, you could think about how much resolution you actually need, and whether it could be reduced.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#rescale base layer; basis for the rest\nBaseLayerFX<-aggregate(Layer1, fact=factor) #factor defined where paths are loaded\n\nLayer2_coarse<-resample(Layer2,BaseLayerFX) #it will match the extent of the baselayer\n#if you aggregate Layer2, there might be slight differences in pixel positions/extents etc-so they may not match\n#it is best to resample using the first one as basis\n\n####\n# save layers you create in between\n###\n#so next time you don't have to re-do them... \n#it saves times for you and it frees up memory both for new processes -and garbage collection gc()\n\n#e.g.\n#writeRaster(Layer2_coarse, filename=file.path(ProcessOut,paste0(\"uchas.tif\")), format=\"GTiff\", overwrite=FALSE)\n```\n:::\n\n\n## The `doParallel` package - Tim Devereux\n\nStill on the subject of memory, Tim showed us how to use the `doParallel` package in R, with a reproducible example.\n\nThis is a very basic example of what is called an embarrassingly parallel task, but should be a nice short intro for absolute beginners to parallel programming.\n\nParallel computing is a complex field of computer science. Performance is dependent on many factors including algorithm complexity, hardware IO performance and input data interdependence. Wikipedia has a nice overview of these topics here: <https://en.wikipedia.org/wiki/Parallel_computing#Types_of_parallelism>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# First we define our function. For the sake of clear example this function just sleeps for n seconds which is given as input.\n\ndo_something <- function(n)\n{\n    Sys.sleep(n)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n### Base R for loop ###\n\n# Define number of iterations\niterations = 6\n\n# Start process timer\nstart <- proc.time()\n\n# Call our function using a base R for loop, this is executed sequentially using one process. \nfor (x in 1:iterations){\n  do_something(1)\n}\n\n# Stop process timer\nbase_loop <- proc.time()-start\n\n\n# Print duration to console\nprint(base_loop)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   user  system elapsed \n   0.00    0.00    6.14 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Import doParallel \nlibrary(doParallel)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: foreach\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: iterators\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: parallel\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Using doParallel.detectCores(), detect the number of cores on your machine.\ndetectCores()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 8\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Using doParallel.registerDoParallel(), allocate a number of cores available for processing in parallel.\nregisterDoParallel(6)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n### doParaellel %do% ###\n\n# Start process timer\nstart <- proc.time()\n\n# Call our function using a doParaellel %do% loop, this is also executed sequentially using one process. \n\nr <- foreach(icount(iterations)) %do% {\n  do_something(1)\n}\n\n# Stop process timer\ndo_loop <- proc.time()-start\n\n# Print duration to console\nprint(do_loop)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   user  system elapsed \n   0.04    0.00    6.15 \n```\n:::\n:::\n\n\nThis takes a similar amount of time to process as base R. Some functions do not gain performance when parallelised or the output of a function may be more reliable when executed as a single process. So in some situations parallelism is not always desired.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### doParaellel %dopar% ###\n  \n# Start process timer\nstart <- proc.time()\n\n# Call our function using a doParaellel %dopar% loop, this is executed in parallel.\nr <- foreach(icount(6)) %dopar% {\n  do_something(1)\n}\n\n# Stop process timer\ndopar_loop <- proc.time()-start\n\n# Print duration to console\nprint(dopar_loop)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   user  system elapsed \n   0.02    0.00    1.08 \n```\n:::\n:::\n\n\nIt takes \\~1 seconds to run the our function on 6 cores. How long would it take on 3 cores, or 12 cores? What happens if we change the number of iterations?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Print concatenated results to console. \nprint(rbind(base_loop,do_loop,dopar_loop)[,1:3])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           user.self sys.self elapsed\nbase_loop       0.00        0    6.14\ndo_loop         0.04        0    6.15\ndopar_loop      0.02        0    1.08\n```\n:::\n:::\n\n\n## Annoying Terra warning - Richard Cottrell\n\nRichard is running some geospatial analysis using the `terra` package.He ultimately wants this code to be free of warnings etc, so he can turn it into a shiny app.\n\nBut is constantly getting this warning: `Error in (function (x) : attempt to apply non-function`\n\nThis is discussed [here](https://github.com/rspatial/terra/issues/30).\n\nWhere Robert Hijmans (the main terra developer), seems to say that it is an annoying problem with no solution.\n\nApril 2022, from Robert Hijmans: \\>You can ignore these messages from the garbage collector. They do not affect your data. They are very annoying. I have done a lot of things to get to the bottom of this, but sofar to no avail. I have much simpler packages that also show these messages and I need to go back to one of these to create a reproducible example for others to look at (even it only happens on the first run) that does not require installation of GDAL etc.\n\nIt appears to be related to the garbage collection R function `gc()`\n\nOne person suggested this as a \"dirty workaround\" `try(terra::XXX, silent = TRUE)`\n\nSo it seems that there is no easy solution to this particular error.\n\n## Coordinate reference system issues in `terra` - Catherine Kim\n\n[This is currently unsolved, so please get in touch if you have a solution]{style=\"color: red;\"}\n\nCatherine is having an issue with reprojecting between rasters with certain EPSG codes in terra.\n\nProject CRS is epsg:28355, but also has one raster in epsg:9001. So trying to convert the 9001 to 28355 and it is not working.\n\nAlso found that when trying to make a reproducible example, got NAs for the reprojected raster - whether reprojecting from 9001 or 28355...\n\nTesting reproject from EPSG 9001 to 4326\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(terra)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nterra 1.6.3\n```\n:::\n\n```{.r .cell-code}\n\t# Create a raster with EPSG:4326 projection\n\ttarget <- rast(nrows=108, ncols=21, xmin=0, xmax=50,\n\t          vals = rep(1:21, each = 2),\n\t          crs = \"EPSG:4326\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: [setValues] values were recycled\n```\n:::\n\n```{.r .cell-code}\n\tplot(target)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\tcrs(target)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"GEOGCRS[\\\"WGS 84\\\",\\n    DATUM[\\\"World Geodetic System 1984\\\",\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\"\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a raster with EPSG:4326 projection \n\ty <- rast(nrows = 54, ncols = 21, xmin = 0, xmax = 50,\n\t          vals = rep(1:21, each = 2),\n\t          crs = \"EPSG:9001\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: [setValues] values were recycled\n```\n:::\n\n```{.r .cell-code}\n\ty\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nclass       : SpatRaster \ndimensions  : 54, 21, 1  (nrow, ncol, nlyr)\nresolution  : 2.380952, 3.333333  (x, y)\nextent      : 0, 50, -90, 90  (xmin, xmax, ymin, ymax)\ncoord. ref. : +proj=geocent +ellps=GRS80 +units=m +no_defs \nsource      : memory \nname        : lyr.1 \nmin value   :     1 \nmax value   :    21 \n```\n:::\n\n```{.r .cell-code}\n\tplot(y)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\t# project to target raster\n\tz <- project(y, target, method = \"near\")\n\tz\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nclass       : SpatRaster \ndimensions  : 108, 21, 1  (nrow, ncol, nlyr)\nresolution  : 2.380952, 1.666667  (x, y)\nextent      : 0, 50, -90, 90  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : memory \nname        : lyr.1 \nmin value   :   NaN \nmax value   :   NaN \n```\n:::\n\n```{.r .cell-code}\n\t# the min/max values are NaN?\n\tplot(z) # blank...\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-2.png){width=672}\n:::\n:::\n\n\n## Incorporating interactive maps into your thesis - Paul Dielmans\n\nPaul is wanting to make some interactive maps as part of his thesis. Some discussion about the options that are out there. \\### Blogdown. One option is to use something like blogdown. There are examples on this website, like Stephanes excellent [work](https://geospatial-community.netlify.app/post/2022-03-31-spatial-networks/) describing tidy networks.\n\n### Leaflet\n\n[Leaflet](https://rstudio.github.io/leaflet/) is another option.\\\nThis might give more flexibility in terms of map making, but doesn't give you the document format.\n\nWe will stay posted with what Paul ends up doing!\n\n## Running arcpy on a supercomputer? - Deqiang MA\n\nDeqiang is wanting to know how to run arcpy on the supercomputer.\n\nBecause Arcpy uses windows, it is not able to be run on any of the university HPCs...\n\nGabriel had had similar issues with arcpy, and confirmed that the HPC will not support arcpy with because it uses linux based clusters\n\nGabriel suggested running arcpy using the multiprocessing library\n\nAn alternative would be to re-code the least cost algorithm using python <https://gis.stackexchange.com/questions/28583/gdal-perform-simple-least-cost-path-analysis>\n\n## How do you debug R code properly?\n\nThere was some discussion of debugging in R. [This](https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-the-RStudio-IDE) post was shared as a starting point.\n\nBecause debugging is something most of thought we could do better at, it might be a good candidate for a workshop down the track.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}